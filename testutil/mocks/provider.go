// =============================================================================
// ğŸ­ MockProvider - LLM Provider æ¨¡æ‹Ÿå®ç°
// =============================================================================
// ç”¨äºæµ‹è¯•çš„ LLM Provider æ¨¡æ‹Ÿï¼Œæ”¯æŒè‡ªå®šä¹‰å“åº”å’Œé”™è¯¯æ³¨å…¥
//
// ä½¿ç”¨æ–¹æ³•:
//
//	provider := mocks.NewMockProvider().
//	    WithResponse("Hello, World!").
//	    WithTokenUsage(100, 50)
//
//	// æˆ–è€…ä½¿ç”¨æµå¼å“åº”
//	provider := mocks.NewMockProvider().
//	    WithStreamChunks([]string{"Hello", ", ", "World", "!"})
// =============================================================================
package mocks

import (
	"context"
	"errors"
	"sync"
	"time"

	"github.com/BaSui01/agentflow/llm"
	"github.com/BaSui01/agentflow/types"
)

// =============================================================================
// ğŸ¯ MockProvider ç»“æ„
// =============================================================================

// MockProvider æ˜¯ LLM Provider çš„æ¨¡æ‹Ÿå®ç°
type MockProvider struct {
	mu sync.RWMutex

	// å“åº”é…ç½®
	response     string
	streamChunks []string
	toolCalls    []types.ToolCall
	err          error

	// Token ä½¿ç”¨ç»Ÿè®¡
	promptTokens     int
	completionTokens int

	// è°ƒç”¨è®°å½•
	calls           []MockProviderCall
	completionFunc  func(ctx context.Context, req *llm.ChatRequest) (*llm.ChatResponse, error)
	streamFunc      func(ctx context.Context, req *llm.ChatRequest) (<-chan llm.StreamChunk, error)

	// è¡Œä¸ºæ§åˆ¶
	delay        int // æ¨¡æ‹Ÿå»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
	failAfter    int // åœ¨ç¬¬ N æ¬¡è°ƒç”¨åå¤±è´¥
	callCount    int
	shouldStream bool
}

// MockProviderCall è®°å½•å•æ¬¡è°ƒç”¨
type MockProviderCall struct {
	Request  *llm.ChatRequest
	Response *llm.ChatResponse
	Error    error
}

// =============================================================================
// ğŸ”§ æ„é€ å‡½æ•°å’Œ Builder æ–¹æ³•
// =============================================================================

// NewMockProvider åˆ›å»ºæ–°çš„ MockProvider
func NewMockProvider() *MockProvider {
	return &MockProvider{
		response:         "Mock response",
		streamChunks:     []string{},
		toolCalls:        []types.ToolCall{},
		calls:            []MockProviderCall{},
		promptTokens:     10,
		completionTokens: 20,
	}
}

// WithResponse è®¾ç½®å›ºå®šå“åº”å†…å®¹
func (m *MockProvider) WithResponse(response string) *MockProvider {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.response = response
	return m
}

// WithError è®¾ç½®è¿”å›é”™è¯¯
func (m *MockProvider) WithError(err error) *MockProvider {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.err = err
	return m
}

// WithStreamChunks è®¾ç½®æµå¼å“åº”å—
func (m *MockProvider) WithStreamChunks(chunks []string) *MockProvider {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.streamChunks = chunks
	m.shouldStream = true
	return m
}

// WithToolCalls è®¾ç½®å·¥å…·è°ƒç”¨å“åº”
func (m *MockProvider) WithToolCalls(toolCalls []types.ToolCall) *MockProvider {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.toolCalls = toolCalls
	return m
}

// WithTokenUsage è®¾ç½® Token ä½¿ç”¨é‡
func (m *MockProvider) WithTokenUsage(prompt, completion int) *MockProvider {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.promptTokens = prompt
	m.completionTokens = completion
	return m
}

// WithDelay è®¾ç½®å“åº”å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
func (m *MockProvider) WithDelay(ms int) *MockProvider {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.delay = ms
	return m
}

// WithFailAfter è®¾ç½®åœ¨ç¬¬ N æ¬¡è°ƒç”¨åå¤±è´¥
func (m *MockProvider) WithFailAfter(n int) *MockProvider {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.failAfter = n
	return m
}

// WithCompletionFunc è®¾ç½®è‡ªå®šä¹‰ Completion å‡½æ•°
func (m *MockProvider) WithCompletionFunc(fn func(ctx context.Context, req *llm.ChatRequest) (*llm.ChatResponse, error)) *MockProvider {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.completionFunc = fn
	return m
}

// WithStreamFunc è®¾ç½®è‡ªå®šä¹‰ Stream å‡½æ•°
func (m *MockProvider) WithStreamFunc(fn func(ctx context.Context, req *llm.ChatRequest) (<-chan llm.StreamChunk, error)) *MockProvider {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.streamFunc = fn
	return m
}

// =============================================================================
// ğŸ¯ Provider æ¥å£å®ç°
// =============================================================================

// Name è¿”å› Provider åç§°
func (m *MockProvider) Name() string {
	return "mock"
}

// SupportsNativeFunctionCalling è¿”å›æ˜¯å¦æ”¯æŒåŸç”Ÿå‡½æ•°è°ƒç”¨
func (m *MockProvider) SupportsNativeFunctionCalling() bool {
	return true
}

// HealthCheck æ‰§è¡Œå¥åº·æ£€æŸ¥
func (m *MockProvider) HealthCheck(ctx context.Context) (*llm.HealthStatus, error) {
	return &llm.HealthStatus{
		Healthy:   true,
		Latency:   10 * time.Millisecond,
		ErrorRate: 0,
	}, nil
}

// Completion ç”Ÿæˆå“åº”
func (m *MockProvider) Completion(ctx context.Context, req *llm.ChatRequest) (*llm.ChatResponse, error) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.callCount++

	// æ£€æŸ¥æ˜¯å¦åº”è¯¥å¤±è´¥
	if m.failAfter > 0 && m.callCount > m.failAfter {
		err := errors.New("mock provider: configured to fail after N calls")
		m.calls = append(m.calls, MockProviderCall{Request: req, Error: err})
		return nil, err
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰é¢„è®¾é”™è¯¯
	if m.err != nil {
		m.calls = append(m.calls, MockProviderCall{Request: req, Error: m.err})
		return nil, m.err
	}

	// ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°
	if m.completionFunc != nil {
		resp, err := m.completionFunc(ctx, req)
		m.calls = append(m.calls, MockProviderCall{Request: req, Response: resp, Error: err})
		return resp, err
	}

	// æ„å»ºé»˜è®¤å“åº”
	msg := types.Message{
		Role:      types.RoleAssistant,
		Content:   m.response,
		ToolCalls: m.toolCalls,
	}

	resp := &llm.ChatResponse{
		ID:       "mock-response-id",
		Provider: "mock",
		Model:    req.Model,
		Choices: []llm.ChatChoice{
			{
				Index:        0,
				FinishReason: "stop",
				Message:      msg,
			},
		},
		Usage: llm.ChatUsage{
			PromptTokens:     m.promptTokens,
			CompletionTokens: m.completionTokens,
			TotalTokens:      m.promptTokens + m.completionTokens,
		},
		CreatedAt: time.Now(),
	}

	if len(m.toolCalls) > 0 {
		resp.Choices[0].FinishReason = "tool_calls"
	}

	m.calls = append(m.calls, MockProviderCall{Request: req, Response: resp})
	return resp, nil
}

// Stream æµå¼ç”Ÿæˆå“åº”
func (m *MockProvider) Stream(ctx context.Context, req *llm.ChatRequest) (<-chan llm.StreamChunk, error) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.callCount++

	// æ£€æŸ¥æ˜¯å¦æœ‰é¢„è®¾é”™è¯¯
	if m.err != nil {
		return nil, m.err
	}

	// ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°
	if m.streamFunc != nil {
		return m.streamFunc(ctx, req)
	}

	// åˆ›å»ºæµå¼å“åº”é€šé“
	ch := make(chan llm.StreamChunk, len(m.streamChunks)+1)

	go func() {
		defer close(ch)

		// å¦‚æœæ²¡æœ‰è®¾ç½®æµå¼å—ï¼Œä½¿ç”¨å®Œæ•´å“åº”
		if len(m.streamChunks) == 0 {
			ch <- llm.StreamChunk{
				ID:       "mock-chunk-id",
				Provider: "mock",
				Model:    req.Model,
				Delta: types.Message{
					Role:    types.RoleAssistant,
					Content: m.response,
				},
				FinishReason: "stop",
			}
			return
		}

		// å‘é€æµå¼å—
		for i, chunk := range m.streamChunks {
			select {
			case <-ctx.Done():
				return
			case ch <- llm.StreamChunk{
				ID:       "mock-chunk-id",
				Provider: "mock",
				Model:    req.Model,
				Index:    i,
				Delta: types.Message{
					Role:    types.RoleAssistant,
					Content: chunk,
				},
				FinishReason: func() string {
					if i == len(m.streamChunks)-1 {
						return "stop"
					}
					return ""
				}(),
			}:
			}
		}
	}()

	return ch, nil
}

// =============================================================================
// ğŸ” æŸ¥è¯¢æ–¹æ³•
// =============================================================================

// GetCalls è·å–æ‰€æœ‰è°ƒç”¨è®°å½•
func (m *MockProvider) GetCalls() []MockProviderCall {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return append([]MockProviderCall{}, m.calls...)
}

// GetCallCount è·å–è°ƒç”¨æ¬¡æ•°
func (m *MockProvider) GetCallCount() int {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.callCount
}

// GetLastCall è·å–æœ€åä¸€æ¬¡è°ƒç”¨
func (m *MockProvider) GetLastCall() *MockProviderCall {
	m.mu.RLock()
	defer m.mu.RUnlock()
	if len(m.calls) == 0 {
		return nil
	}
	call := m.calls[len(m.calls)-1]
	return &call
}

// Reset é‡ç½®æ‰€æœ‰çŠ¶æ€
func (m *MockProvider) Reset() {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.calls = []MockProviderCall{}
	m.callCount = 0
	m.err = nil
}

// =============================================================================
// ğŸ­ é¢„è®¾ Provider å·¥å‚
// =============================================================================

// NewSuccessProvider åˆ›å»ºæ€»æ˜¯æˆåŠŸçš„ Provider
func NewSuccessProvider(response string) *MockProvider {
	return NewMockProvider().WithResponse(response)
}

// NewErrorProvider åˆ›å»ºæ€»æ˜¯å¤±è´¥çš„ Provider
func NewErrorProvider(err error) *MockProvider {
	return NewMockProvider().WithError(err)
}

// NewToolCallProvider åˆ›å»ºè¿”å›å·¥å…·è°ƒç”¨çš„ Provider
func NewToolCallProvider(toolCalls []types.ToolCall) *MockProvider {
	return NewMockProvider().WithToolCalls(toolCalls)
}

// NewStreamProvider åˆ›å»ºæµå¼å“åº”çš„ Provider
func NewStreamProvider(chunks []string) *MockProvider {
	return NewMockProvider().WithStreamChunks(chunks)
}

// NewFlakeyProvider åˆ›å»ºä¸ç¨³å®šçš„ Providerï¼ˆé—´æ­‡æ€§å¤±è´¥ï¼‰
func NewFlakeyProvider(failAfter int, response string) *MockProvider {
	return NewMockProvider().
		WithResponse(response).
		WithFailAfter(failAfter)
}
