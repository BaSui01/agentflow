// 版权所有 2024 AgentFlow Authors. 版权所有。
// 此源代码的使用由 MIT 许可规范,该许可可以是
// 在LICENSE文件中找到。

/*
包 llm 提供统一的大语言模型接入层，包括 Provider 抽象、路由、
缓存、重试、可观测与工具调用等能力。

# 概述

本包目标是屏蔽不同模型服务商在接口、鉴权、错误语义和流式协议上的差异，
对上层业务暴露一致的请求与响应模型，降低多模型接入和切换成本。

你可以使用它完成以下典型场景：

- 单一 Provider 的快速接入与调用。
- 多 Provider 路由与故障转移。
- 流式输出、函数调用与工具编排。
- 缓存、重试、熔断、限流与成本观测。

# Provider 抽象

核心接口是 `Provider`，包含补全、流式输出、健康检查与能力声明。
基于该接口，系统可以在保持上层调用不变的前提下切换底层模型服务。

# 主要能力

- 路由与策略：支持按模型、标签、健康状态或策略选择目标 Provider。
- 流式处理：统一流式分片结构，便于实时输出与增量聚合。
- 韧性机制：支持重试、退避、熔断、超时与降级。
- 多级缓存：支持本地与远端缓存协同，减少重复调用。
- 可观测性：支持指标、追踪与成本统计。
- 工具调用：支持函数调用与工具执行闭环。

# 集成建议

- 单 Provider 场景，优先直接使用对应实现并开启基础重试。
- 多 Provider 场景，优先通过路由器统一入口并配置回退策略。
- 高并发场景，建议叠加限流、缓存和熔断配置。
- 生产场景，建议启用观测能力并接入统一告警。

# 相关子包

- `llm/providers`：各模型服务商适配实现。
- `llm/router`：路由策略与选择逻辑。
- `llm/cache`：缓存实现与策略。
- `llm/retry`：重试与退避策略。
- `llm/observability`：指标、追踪与成本观测。
- `llm/tools`：工具调用、ReAct 执行与外部工具集成。
*/
package llm
