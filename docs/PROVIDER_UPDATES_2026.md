# Provider å±‚ 2026 å¹´æ›´æ–°æŒ‡å—

## é‡å¤§å˜åŒ–æ€»è§ˆ

### 1. OpenAI - Responses API è¿ç§»ï¼ˆé‡è¦ï¼‰

**Assistant API å°†äº 2026å¹´8æœˆ26æ—¥ä¸‹çº¿**

- âœ… **æ–° API**: Responses API (`/v1/responses`)
- âŒ **åºŸå¼ƒ**: Assistants API (2026-08-26 ä¸‹çº¿)
- ğŸ†• **GPT-5**: 272K context, $1.25/M tokens
- ğŸ†• **å†…ç½®å·¥å…·**: Web Search, File Search, Computer Use

**è¿ç§»è¦ç‚¹**:
```go
// å¯ç”¨ Responses API
cfg := providers.OpenAIConfig{
    APIKey: "sk-xxx",
    UseResponsesAPI: true, // æ–°å¢é…ç½®
}
```

**Thought Signatures**: æ–° API è¿”å›åŠ å¯†çš„æ¨ç†ç­¾åï¼Œéœ€åœ¨åç»­è°ƒç”¨ä¸­ä¼ é€’ä»¥ä¿æŒæ¨ç†é“¾ã€‚

### 2. Claude (Anthropic) - é‡å¤§å‡çº§

**æ¨¡å‹æ›´æ–°**:
- âœ… **Claude Opus 4.5**: $5/$25 (é™ä»·66%), 1M context
- âœ… **Claude Sonnet 4.5**: æ··åˆæ¨ç†æ¨¡å¼
- âœ… **Claude Haiku 4.5**: $1/$5 (é™ä»·67%)
- âŒ **Claude Opus 3**: 2026-01-05 å·²ä¸‹çº¿

**æ–°ç‰¹æ€§**:
- 1M tokens ä¸Šä¸‹æ–‡çª—å£ (5x æå‡)
- æ··åˆæ¨ç†æ¶æ„ (å¿«é€Ÿ/æ·±åº¦æ€è€ƒæ¨¡å¼)
- æ”¹è¿›çš„å·¥å…·ç¼–æ’
- Memory Tool æ”¯æŒ

**API å˜åŒ–**:
```go
// éœ€è¦æ›´æ–°æ¨¡å‹åç§°
req := &llm.ChatRequest{
    Model: "claude-opus-4.5-20260105", // æ–°ç‰ˆæœ¬
}
```

### 3. Gemini (Google) - Gemini 3 å‘å¸ƒ

**é‡å¤§æ›´æ–°**:
- ğŸ†• **Gemini 3 Pro**: æœ€æ™ºèƒ½æ¨¡å‹
- ğŸ†• **Gemini 3 Flash**: é—ªç”µé€Ÿåº¦
- ğŸ†• **Thought Signatures**: å¿…é¡»ä¼ é€’ä»¥ä¿æŒæ¨ç†é“¾
- ğŸ†• **media_resolution**: ç²¾ç»†æ§åˆ¶å¤šæ¨¡æ€ token ä½¿ç”¨

**API å˜åŒ–**:
```go
// Thought Signatures (å¿…éœ€)
type GeminiRequest struct {
    // ... å…¶ä»–å­—æ®µ
    ThoughtSignatures []string `json:"thought_signatures,omitempty"`
}

// Media Resolution æ§åˆ¶
type MediaConfig struct {
    Resolution string `json:"resolution"` // "low", "medium", "high"
}
```

**ä¸Šä¸‹æ–‡çª—å£**:
- Gemini 3 Pro: 1M tokens
- Gemini 1.5 Pro: 2M tokens (éƒ¨åˆ†å·¥ä½œæµ)

### 4. DeepSeek - V3.1 æ··åˆæ¨ç†

**æ¨¡å‹æ›´æ–°**:
- âœ… **DeepSeek-V3.1-Terminus**: æœ€æ–°ç‰ˆæœ¬
- âœ… **æ··åˆæ¨ç†**: `deepseek-chat` (å¿«é€Ÿ) / `deepseek-reasoner` (æ€è€ƒ)
- ğŸ†• **Agent èƒ½åŠ›**: Code Agent, Search Agent

**æ€§èƒ½æå‡**:
- AIME 2025: 70.0 â†’ 87.5 (+17.5)
- GPQA: 71.5 â†’ 81.0 (+9.5)
- SWE-bench: 66.0

**API ä½¿ç”¨**:
```go
// å¿«é€Ÿæ¨¡å¼
req := &llm.ChatRequest{
    Model: "deepseek-chat",
}

// æ¨ç†æ¨¡å¼
req := &llm.ChatRequest{
    Model: "deepseek-reasoner",
}
```

### 5. Qwen (é€šä¹‰åƒé—®) - Qwen 3 å‘å¸ƒ

**é‡å¤§æ›´æ–°**:
- ğŸ†• **Qwen 3**: 2026-04-29 å‘å¸ƒ
- ğŸ†• **Qwen3-235B-A22B**: æ——èˆ°æ¨¡å‹
- ğŸ†• **Qwen3-Coder-480B**: ä»£ç ä¸“ç”¨
- ğŸ“ˆ **ä¸Šä¸‹æ–‡**: 256K native, 1M with extrapolation

**è®­ç»ƒæ•°æ®**: 36 trillion tokens (2x Qwen2.5)

**API å…¼å®¹**: å®Œå…¨å…¼å®¹ OpenAI æ ¼å¼

### 6. Mistral AI - Mistral 3 ç³»åˆ—

**æ–°æ¨¡å‹**:
- ğŸ†• **Mistral Large 3**: 675B total, 41B active (MoE)
- ğŸ†• **Mistral 3 (14B/8B/3B)**: å¯†é›†æ¨¡å‹
- ğŸ†• **è§†è§‰æ”¯æŒ**: å¤šæ¨¡æ€èƒ½åŠ›
- ğŸ†• **æ¨ç†æ¨¡å¼**: 2025-09 æ›´æ–°

**ç‰¹æ€§**:
- OpenAI å…¼å®¹ API
- åŸç”Ÿ Function Calling
- OCR API (table_format, hyperlinks)

## ä¸Šä¸‹æ–‡çª—å£å¯¹æ¯” (2026)

| Provider | Model | Context | å®é™…å¯ç”¨ |
|----------|-------|---------|---------|
| OpenAI | GPT-5.2 | 272K | ~180K |
| Claude | Opus 4.5 | 1M | ~850K |
| Gemini | 3 Pro | 1M | ~850K |
| Gemini | 1.5 Pro | 2M | ~1.7M |
| DeepSeek | V3.1 | 128K | ~100K |
| Qwen | Qwen3 | 256K-1M | ~200K-850K |
| Llama | 4 Scout | 10M | ~8.5M |

**æ³¨æ„**: å®é™…å¯ç”¨çº¦ä¸ºå®£ä¼ å€¼çš„ 85%

## å®šä»·å˜åŒ– (2026)

### é™ä»·è¶‹åŠ¿

| Provider | Model | æ—§ä»·æ ¼ | æ–°ä»·æ ¼ | é™å¹… |
|----------|-------|--------|--------|------|
| Claude | Opus 4.5 | $15/$75 | $5/$25 | -66% |
| Claude | Haiku 4.5 | $3/$15 | $1/$5 | -67% |
| OpenAI | GPT-5 | - | $1.25/M | æ–°æ¨¡å‹ |

## å¿…é¡»æ›´æ–°çš„ä»£ç 

### 1. OpenAI Provider

```go
// providers/openai/provider.go

// æ·»åŠ  Thought Signatures æ”¯æŒ
type openAIRequest struct {
    // ... ç°æœ‰å­—æ®µ
    PreviousResponseID string `json:"previous_response_id,omitempty"` // æ–°å¢
    Store              bool   `json:"store,omitempty"`                // æ–°å¢
}

// æ·»åŠ  Responses API ç«¯ç‚¹
func (p *OpenAIProvider) completionWithResponsesAPI(ctx context.Context, req *llm.ChatRequest, apiKey string) (*llm.ChatResponse, error) {
    // å·²å®ç°
}
```

### 2. Claude Provider

```go
// providers/anthropic/provider.go

// æ›´æ–°é»˜è®¤æ¨¡å‹
const (
    DefaultModel = "claude-opus-4.5-20260105" // æ›´æ–°
)

// æ·»åŠ æ··åˆæ¨ç†æ¨¡å¼æ”¯æŒ
type ClaudeRequest struct {
    // ... ç°æœ‰å­—æ®µ
    ReasoningMode string `json:"reasoning_mode,omitempty"` // "fast" | "extended"
}
```

### 3. Gemini Provider

```go
// providers/gemini/provider.go

// æ·»åŠ  Thought Signatures
type GeminiRequest struct {
    // ... ç°æœ‰å­—æ®µ
    ThoughtSignatures []string      `json:"thought_signatures,omitempty"`
    MediaResolution   *MediaConfig  `json:"media_resolution,omitempty"`
}

type MediaConfig struct {
    Resolution string `json:"resolution"` // "low", "medium", "high"
}
```

### 4. DeepSeek Provider

```go
// providers/deepseek/provider.go

// æ›´æ–°é»˜è®¤æ¨¡å‹
const (
    DefaultChatModel     = "deepseek-chat"     // V3.1-Terminus
    DefaultReasonerModel = "deepseek-reasoner" // V3.1-Terminus Think
)
```

### 5. Qwen Provider

```go
// providers/qwen/provider.go

// æ›´æ–°é»˜è®¤æ¨¡å‹
const (
    DefaultModel = "qwen3-235b-a22b" // æ›´æ–°åˆ° Qwen3
)

// æ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡
func (p *QwenProvider) supportsExtendedContext() bool {
    return true // 256K-1M
}
```

## æ–°å¢åŠŸèƒ½æ”¯æŒ

### 1. æ··åˆæ¨ç†æ¨¡å¼

```go
// llm/types.go

type ChatRequest struct {
    // ... ç°æœ‰å­—æ®µ
    ReasoningMode string `json:"reasoning_mode,omitempty"` // "fast" | "extended" | "thinking"
}
```

### 2. Thought Signatures

```go
// llm/types.go

type ChatRequest struct {
    // ... ç°æœ‰å­—æ®µ
    ThoughtSignatures []string `json:"thought_signatures,omitempty"`
}

type ChatResponse struct {
    // ... ç°æœ‰å­—æ®µ
    ThoughtSignatures []string `json:"thought_signatures,omitempty"`
}
```

### 3. å¤šæ¨¡æ€åˆ†è¾¨ç‡æ§åˆ¶

```go
// llm/types.go

type MediaResolution struct {
    Resolution string `json:"resolution"` // "low", "medium", "high"
    MaxTokens  int    `json:"max_tokens,omitempty"`
}

type ChatRequest struct {
    // ... ç°æœ‰å­—æ®µ
    MediaResolution *MediaResolution `json:"media_resolution,omitempty"`
}
```

## è¿ç§»æ£€æŸ¥æ¸…å•

### é«˜ä¼˜å…ˆçº§ (å¿…é¡»)

- [ ] OpenAI: è¿ç§»åˆ° Responses API (2026-08-26 å‰)
- [ ] Claude: æ›´æ–°æ¨¡å‹åç§°åˆ° 4.5 ç³»åˆ—
- [ ] Gemini: æ·»åŠ  Thought Signatures æ”¯æŒ
- [ ] æ‰€æœ‰: æ›´æ–°ä¸Šä¸‹æ–‡çª—å£é™åˆ¶

### ä¸­ä¼˜å…ˆçº§ (æ¨è)

- [ ] æ·»åŠ æ··åˆæ¨ç†æ¨¡å¼æ”¯æŒ
- [ ] å®ç° Thought Signatures ä¼ é€’
- [ ] æ›´æ–°é»˜è®¤æ¨¡å‹åˆ°æœ€æ–°ç‰ˆæœ¬
- [ ] æ·»åŠ å¤šæ¨¡æ€åˆ†è¾¨ç‡æ§åˆ¶

### ä½ä¼˜å…ˆçº§ (å¯é€‰)

- [ ] ä¼˜åŒ–è¶…é•¿ä¸Šä¸‹æ–‡å¤„ç†
- [ ] æ·»åŠ æ–°æ¨¡å‹çš„ç‰¹å®šä¼˜åŒ–
- [ ] å®ç°æˆæœ¬ä¼˜åŒ–ç­–ç•¥

## æµ‹è¯•å»ºè®®

### 1. å…¼å®¹æ€§æµ‹è¯•

```bash
# æµ‹è¯•æ‰€æœ‰ Provider
go test ./providers/... -v

# æµ‹è¯•é›†æˆ
go test ./tests/integration/... -v
```

### 2. ä¸Šä¸‹æ–‡çª—å£æµ‹è¯•

```go
func TestLongContext(t *testing.T) {
    providers := []struct {
        name    string
        maxCtx  int
        safeCtx int
    }{
        {"gpt-5", 272000, 230000},
        {"claude-opus-4.5", 1000000, 850000},
        {"gemini-3-pro", 1000000, 850000},
    }
    
    for _, p := range providers {
        t.Run(p.name, func(t *testing.T) {
            // æµ‹è¯•æ¥è¿‘ä¸Šé™çš„ä¸Šä¸‹æ–‡
        })
    }
}
```

### 3. æ–°ç‰¹æ€§æµ‹è¯•

```go
func TestThoughtSignatures(t *testing.T) {
    // æµ‹è¯• Thought Signatures ä¼ é€’
}

func TestHybridReasoning(t *testing.T) {
    // æµ‹è¯•æ··åˆæ¨ç†æ¨¡å¼
}
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ä¸Šä¸‹æ–‡ç®¡ç†

```go
// å®ç°æ™ºèƒ½ä¸Šä¸‹æ–‡å‹ç¼©
func (m *ContextManager) CompressForProvider(ctx string, provider string) string {
    limits := map[string]int{
        "gpt-5":          230000,
        "claude-opus-4.5": 850000,
        "gemini-3-pro":    850000,
    }
    
    maxTokens := limits[provider]
    if len(ctx) > maxTokens {
        return m.compress(ctx, maxTokens)
    }
    return ctx
}
```

### 2. æˆæœ¬ä¼˜åŒ–

```go
// æ ¹æ®ä»»åŠ¡é€‰æ‹©æœ€ä¼˜æ¨¡å‹
func SelectOptimalModel(task Task) string {
    if task.RequiresReasoning {
        return "deepseek-reasoner" // ä¾¿å®œä¸”å¼ºå¤§
    }
    if task.RequiresSpeed {
        return "gemini-3-flash" // æœ€å¿«
    }
    if task.RequiresQuality {
        return "claude-opus-4.5" // æœ€å¥½
    }
    return "gpt-5" // å¹³è¡¡
}
```

## å‚è€ƒèµ„æº

- [OpenAI Responses API](https://developers.openai.com/blog/responses-api)
- [Claude 4.5 Release](https://www.anthropic.com/news/claude-opus-4-5)
- [Gemini 3 Guide](https://ai.google.dev/gemini-api/docs/gemini-3)
- [DeepSeek V3.1 Updates](https://api-docs.deepseek.com/updates/)
- [Qwen 3 Release](https://github.com/QwenLM/Qwen3)
- [Mistral 3 Announcement](https://mistral.ai/news/mistral-3)

## æ›´æ–°æ—¶é—´çº¿

| æ—¥æœŸ | äº‹ä»¶ |
|------|------|
| 2025-12 | GPT-5.2, Gemini 3 å‘å¸ƒ |
| 2026-01-05 | Claude Opus 3 ä¸‹çº¿ |
| 2026-04-29 | Qwen 3 å‘å¸ƒ |
| 2026-05-28 | DeepSeek V3.1 å‘å¸ƒ |
| 2026-08-26 | OpenAI Assistants API ä¸‹çº¿ âš ï¸ |

---

**æœ€åæ›´æ–°**: 2026-01-26
