# 多模态处理

AgentFlow 提供完整的多模态内容处理能力，支持图像、音频、视频的输入理解和生成。

## 多模态内容类型

```go
import "github.com/BaSui01/agentflow/llm/multimodal"

// 支持的内容类型
const (
    ContentTypeText     = "text"
    ContentTypeImage    = "image"
    ContentTypeAudio    = "audio"
    ContentTypeVideo    = "video"
    ContentTypeDocument = "document"
)
```

## 图像处理

### 图像输入

```go
// 从 URL 创建图像内容
imageContent := multimodal.NewImageURLContent("https://example.com/image.png")

// 从 Base64 创建
imageContent := multimodal.NewImageBase64Content(base64Data, multimodal.ImageFormatPNG)

// 从文件加载
imageContent, err := multimodal.LoadImageFromFile("./image.png")

// 从 URL 下载并加载
imageContent, err := multimodal.LoadImageFromURL("https://example.com/image.png")
```

### 图像生成

```go
import "github.com/BaSui01/agentflow/llm/image"

// OpenAI DALL-E
provider := image.NewOpenAIImageProvider(image.OpenAIConfig{
    APIKey: os.Getenv("OPENAI_API_KEY"),
})

// 生成图像
resp, err := provider.Generate(ctx, &image.GenerateRequest{
    Prompt:         "一只可爱的猫咪在阳光下睡觉",
    NegativePrompt: "模糊, 低质量",
    Model:          "dall-e-3",
    N:              1,
    Size:           "1024x1024",
    Quality:        "hd",
    Style:          "vivid",
    ResponseFormat: "url",
})

for _, img := range resp.Images {
    fmt.Printf("图像 URL: %s\n", img.URL)
    fmt.Printf("修改后的提示: %s\n", img.RevisedPrompt)
}

// 图像编辑
editResp, err := provider.Edit(ctx, &image.EditRequest{
    Image:  imageReader,
    Mask:   maskReader,
    Prompt: "将背景改为海滩",
    Size:   "1024x1024",
})

// 图像变体
varResp, err := provider.CreateVariation(ctx, &image.VariationRequest{
    Image: imageReader,
    N:     3,
    Size:  "1024x1024",
})
```

### Flux 图像生成

```go
fluxProvider := image.NewFluxProvider(image.FluxConfig{
    APIKey:  os.Getenv("FLUX_API_KEY"),
    BaseURL: "https://api.flux.ai/v1",
})

resp, err := fluxProvider.Generate(ctx, &image.GenerateRequest{
    Prompt:   "赛博朋克风格的城市夜景",
    Model:    "flux-pro",
    Steps:    30,
    CFGScale: 7.5,
    Seed:     42,
})
```

## 音频处理

### 语音合成 (TTS)

```go
import "github.com/BaSui01/agentflow/llm/speech"

// OpenAI TTS
ttsProvider := speech.NewOpenAITTSProvider(speech.OpenAITTSConfig{
    APIKey: os.Getenv("OPENAI_API_KEY"),
})

resp, err := ttsProvider.Synthesize(ctx, &speech.TTSRequest{
    Text:           "你好，欢迎使用 AgentFlow！",
    Model:          "tts-1-hd",
    Voice:          "alloy",
    Speed:          1.0,
    ResponseFormat: "mp3",
})

// 读取音频流
audioData, _ := io.ReadAll(resp.Audio)

// 直接保存到文件
err = ttsProvider.SynthesizeToFile(ctx, &speech.TTSRequest{
    Text:  "保存到文件的语音",
    Voice: "nova",
}, "output.mp3")

// 列出可用声音
voices, _ := ttsProvider.ListVoices(ctx)
for _, v := range voices {
    fmt.Printf("声音: %s (%s)\n", v.Name, v.Language)
}
```

### ElevenLabs TTS

```go
elevenProvider := speech.NewElevenLabsProvider(speech.ElevenLabsConfig{
    APIKey: os.Getenv("ELEVENLABS_API_KEY"),
})

resp, err := elevenProvider.Synthesize(ctx, &speech.TTSRequest{
    Text:     "高质量语音合成",
    Voice:    "Rachel",
    Language: "zh-CN",
})
```

### 语音识别 (STT)

```go
// OpenAI Whisper
sttProvider := speech.NewOpenAISTTProvider(speech.OpenAISTTConfig{
    APIKey: os.Getenv("OPENAI_API_KEY"),
})

resp, err := sttProvider.Transcribe(ctx, &speech.STTRequest{
    Audio:          audioReader,
    Model:          "whisper-1",
    Language:       "zh",
    ResponseFormat: "verbose_json",
    TimestampGranularities: []string{"word", "segment"},
})

fmt.Printf("转录文本: %s\n", resp.Text)
fmt.Printf("语言: %s\n", resp.Language)
fmt.Printf("时长: %v\n", resp.Duration)

// 查看分段
for _, seg := range resp.Segments {
    fmt.Printf("[%v - %v] %s\n", seg.Start, seg.End, seg.Text)
}

// 查看词级时间戳
for _, word := range resp.Words {
    fmt.Printf("%s (%v - %v)\n", word.Word, word.Start, word.End)
}

// 从文件转录
resp, err = sttProvider.TranscribeFile(ctx, "audio.mp3", &speech.STTRequest{
    Language: "zh",
})
```

### Deepgram STT

```go
deepgramProvider := speech.NewDeepgramProvider(speech.DeepgramConfig{
    APIKey: os.Getenv("DEEPGRAM_API_KEY"),
})

resp, err := deepgramProvider.Transcribe(ctx, &speech.STTRequest{
    Audio:       audioReader,
    Language:    "zh",
    Diarization: true, // 说话人识别
})

// 查看说话人分离结果
for _, seg := range resp.Segments {
    fmt.Printf("[%s] %s\n", seg.Speaker, seg.Text)
}
```

## 视频处理

### 视频分析

```go
import "github.com/BaSui01/agentflow/llm/video"

// Gemini 视频分析
geminiVideo := video.NewGeminiVideoProvider(video.GeminiConfig{
    APIKey: os.Getenv("GEMINI_API_KEY"),
})

resp, err := geminiVideo.Analyze(ctx, &video.AnalyzeRequest{
    VideoURL:  "https://example.com/video.mp4",
    Prompt:    "描述这个视频的内容，识别其中的人物和动作",
    Model:     "gemini-3-pro-vision",
    MaxFrames: 10,
    Interval:  2.0, // 每 2 秒采样一帧
})

fmt.Printf("视频描述: %s\n", resp.Content)

// 查看帧分析
for _, frame := range resp.Frames {
    fmt.Printf("时间 %.1fs: %s\n", frame.Timestamp, frame.Description)
    for _, obj := range frame.Objects {
        fmt.Printf("  检测到: %s (%.2f)\n", obj.Label, obj.Confidence)
    }
}
```

### 视频生成

```go
// Runway 视频生成
runwayProvider := video.NewRunwayProvider(video.RunwayConfig{
    APIKey: os.Getenv("RUNWAY_API_KEY"),
})

resp, err := runwayProvider.Generate(ctx, &video.GenerateRequest{
    Prompt:      "一只蝴蝶在花丛中飞舞",
    Model:       "gen-3",
    Duration:    4.0,
    AspectRatio: "16:9",
    Resolution:  "1080p",
})

fmt.Printf("视频 URL: %s\n", resp.Videos[0].URL)

// 图生视频
resp, err = runwayProvider.Generate(ctx, &video.GenerateRequest{
    Prompt:   "让图片中的人物微笑",
    ImageURL: "https://example.com/portrait.jpg",
    Duration: 3.0,
})

// Google Veo 视频生成
veoProvider := video.NewVeoProvider(video.VeoConfig{
    APIKey: os.Getenv("GOOGLE_API_KEY"),
})

resp, err := veoProvider.Generate(ctx, &video.GenerateRequest{
    Prompt:      "日落时分的海滩，海浪轻轻拍打沙滩",
    Duration:    5.0,
    AspectRatio: "16:9",
})
```

## 多模态消息

构建包含多种内容类型的消息：

```go
// 创建多模态消息
msg := multimodal.MultimodalMessage{
    Role: "user",
    Contents: []multimodal.Content{
        multimodal.NewTextContent("请分析这张图片中的内容"),
        multimodal.NewImageURLContent("https://example.com/image.png"),
    },
}

// 添加音频
audioContent, _ := multimodal.LoadAudioFromFile("audio.mp3")
msg.Contents = append(msg.Contents, audioContent)
```

## 配置选项

### 视觉配置

```go
visionConfig := multimodal.VisionConfig{
    Resolution:     multimodal.ResolutionHigh,
    MaxImageSize:   20 * 1024 * 1024, // 20MB
    MaxDimension:   4096,
    AllowedFormats: []multimodal.ImageFormat{
        multimodal.ImageFormatPNG,
        multimodal.ImageFormatJPEG,
        multimodal.ImageFormatWebP,
    },
}
```

### 音频配置

```go
audioConfig := multimodal.AudioConfig{
    MaxDuration:    300, // 5 分钟
    MaxFileSize:    25 * 1024 * 1024,
    SampleRate:     16000,
    AllowedFormats: []multimodal.AudioFormat{
        multimodal.AudioFormatMP3,
        multimodal.AudioFormatWAV,
        multimodal.AudioFormatFLAC,
    },
}
```

## 多模态路由

根据内容类型自动路由到合适的处理器：

```go
import "github.com/BaSui01/agentflow/llm/multimodal"

router := multimodal.NewRouter(multimodal.RouterConfig{
    TextProvider:  openaiProvider,
    ImageProvider: geminiProvider,
    AudioProvider: whisperProvider,
    VideoProvider: geminiVideoProvider,
})

// 自动路由处理
result, err := router.Process(ctx, content)
```

## 最佳实践

1. **图像优化**：大图像先压缩再上传，节省成本
2. **音频格式**：优先使用 MP3/WAV，兼容性最好
3. **视频采样**：合理设置采样间隔，平衡精度和成本
4. **错误处理**：多模态处理耗时较长，设置合理超时
5. **成本控制**：多模态 API 成本较高，注意监控用量
