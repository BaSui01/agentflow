# 检索增强 (RAG)

AgentFlow 提供完整的 RAG 实现，支持混合检索、向量存储、重排序、上下文管理等功能。

## 混合检索

结合 BM25 和向量检索的混合检索器：

```go
import "github.com/BaSui01/agentflow/llm/retrieval"

// 创建混合检索器
retriever := retrieval.NewHybridRetriever(retrieval.HybridRetrievalConfig{
    // BM25 配置
    UseBM25:    true,
    BM25Weight: 0.5,
    BM25K1:     1.5,
    BM25B:      0.75,
    
    // 向量检索配置
    UseVector:    true,
    VectorWeight: 0.5,
    
    // 重排序配置
    UseReranking: true,
    RerankTopK:   50,
    
    // 检索参数
    TopK:     5,
    MinScore: 0.3,
}, logger)

// 索引文档
docs := []retrieval.Document{
    {
        ID:        "doc1",
        Content:   "Go 是一种静态类型的编译语言...",
        Metadata:  map[string]interface{}{"source": "wiki"},
        Embedding: embedding1,
    },
    {
        ID:        "doc2",
        Content:   "并发是 Go 的核心特性之一...",
        Metadata:  map[string]interface{}{"source": "blog"},
        Embedding: embedding2,
    },
}

retriever.IndexDocuments(docs)

// 检索
results, err := retriever.Retrieve(ctx, "Go 并发编程", queryEmbedding)

for _, r := range results {
    fmt.Printf("文档: %s\n", r.Document.ID)
    fmt.Printf("内容: %s\n", r.Document.Content)
    fmt.Printf("BM25 分数: %.3f\n", r.BM25Score)
    fmt.Printf("向量分数: %.3f\n", r.VectorScore)
    fmt.Printf("混合分数: %.3f\n", r.HybridScore)
    fmt.Printf("最终分数: %.3f\n", r.FinalScore)
}
```

## 向量存储

### 内置向量存储

```go
// 创建带向量存储的检索器
vectorStore := retrieval.NewInMemoryVectorStore()
retriever := retrieval.NewHybridRetrieverWithVectorStore(config, vectorStore, logger)
```

### Qdrant 集成

```go
vectorStore := retrieval.NewQdrantStore(retrieval.QdrantConfig{
    Host:       "localhost",
    Port:       6333,
    Collection: "documents",
    Dimension:  1536,
})

// 添加文档
vectorStore.AddDocuments(ctx, docs)

// 搜索
results, _ := vectorStore.Search(ctx, queryVector, 10)
```

### Pinecone 集成

```go
vectorStore := retrieval.NewPineconeStore(retrieval.PineconeConfig{
    APIKey:      os.Getenv("PINECONE_API_KEY"),
    Environment: "us-west1-gcp",
    Index:       "documents",
})
```

## Embedding 提供商

### OpenAI Embedding

```go
import "github.com/BaSui01/agentflow/llm/embedding"

embedder := embedding.NewOpenAIEmbedder(embedding.OpenAIConfig{
    APIKey: os.Getenv("OPENAI_API_KEY"),
    Model:  "text-embedding-3-large",
})

// 生成单个 Embedding
vector, err := embedder.Embed(ctx, "Go 并发编程")

// 批量生成
vectors, err := embedder.EmbedBatch(ctx, []string{
    "文本 1",
    "文本 2",
    "文本 3",
})
```

### 其他 Embedding 提供商

```go
// Cohere
cohereEmbedder := embedding.NewCohereEmbedder(embedding.CohereConfig{
    APIKey: os.Getenv("COHERE_API_KEY"),
    Model:  "embed-multilingual-v3.0",
})

// Voyage AI
voyageEmbedder := embedding.NewVoyageEmbedder(embedding.VoyageConfig{
    APIKey: os.Getenv("VOYAGE_API_KEY"),
    Model:  "voyage-large-2",
})

// Jina
jinaEmbedder := embedding.NewJinaEmbedder(embedding.JinaConfig{
    APIKey: os.Getenv("JINA_API_KEY"),
    Model:  "jina-embeddings-v2-base-zh",
})

// Gemini
geminiEmbedder := embedding.NewGeminiEmbedder(embedding.GeminiConfig{
    APIKey: os.Getenv("GEMINI_API_KEY"),
    Model:  "embedding-001",
})
```

## 重排序

### Cohere Reranker

```go
import "github.com/BaSui01/agentflow/llm/rerank"

reranker := rerank.NewCohereReranker(rerank.CohereConfig{
    APIKey: os.Getenv("COHERE_API_KEY"),
    Model:  "rerank-multilingual-v3.0",
})

// 重排序
rerankedDocs, err := reranker.Rerank(ctx, query, documents, 10)
```

### Voyage Reranker

```go
reranker := rerank.NewVoyageReranker(rerank.VoyageConfig{
    APIKey: os.Getenv("VOYAGE_API_KEY"),
    Model:  "rerank-1",
})
```

### Jina Reranker

```go
reranker := rerank.NewJinaReranker(rerank.JinaConfig{
    APIKey: os.Getenv("JINA_API_KEY"),
    Model:  "jina-reranker-v1-base-zh",
})
```

## 文档分块

```go
import "github.com/BaSui01/agentflow/llm/retrieval"

chunker := retrieval.NewChunker(retrieval.ChunkConfig{
    ChunkSize:    512,
    ChunkOverlap: 50,
    Separator:    "\n\n",
})

// 分块
chunks := chunker.Split(longDocument)

// 带元数据的分块
chunksWithMeta := chunker.SplitWithMetadata(longDocument, map[string]interface{}{
    "source": "document.pdf",
    "page":   1,
})
```

## 上下文检索

结合上下文的智能检索：

```go
contextualRetriever := retrieval.NewContextualRetriever(retrieval.ContextualConfig{
    BaseRetriever: retriever,
    LLMProvider:   provider,
    MaxContext:    3,
    ContextPrompt: "基于以下上下文回答问题:\n\n{{context}}\n\n问题: {{query}}",
})

// 检索并生成上下文
context, err := contextualRetriever.RetrieveWithContext(ctx, query)
```

## 图 RAG

基于知识图谱的检索：

```go
graphRAG := retrieval.NewGraphRAG(retrieval.GraphRAGConfig{
    VectorStore:    vectorStore,
    KnowledgeGraph: neo4jGraph,
    MaxHops:        2,
    CombineWeight:  0.7,
})

// 图增强检索
results, err := graphRAG.Retrieve(ctx, query, queryEmbedding)
```

## 上下文管理

### 上下文裁剪

```go
import "github.com/BaSui01/agentflow/llm/context"

manager := context.NewDefaultContextManager(tokenizer, logger)

// 裁剪消息以适应 Token 限制
trimmedMsgs, err := manager.TrimMessages(messages, 4096)

// 按策略裁剪
trimmedMsgs, err = manager.PruneByStrategy(messages, 4096, context.PruneOldest)
```

### 裁剪策略

| 策略 | 说明 |
|------|------|
| `PruneOldest` | 删除最旧的消息，保留 System 和最近消息 |
| `PruneByRole` | 按角色优先级裁剪 (System > User/Assistant > Tool) |
| `PruneLeastImportant` | 按重要性裁剪（需要 Metadata.importance） |
| `PruneSlidingWindow` | 滑动窗口，保留最近 N 条 |
| `PruneToolCalls` | 优先删除工具调用和结果 |

### 摘要压缩

```go
compressor := context.NewSummaryCompressor(context.SummaryConfig{
    Provider:       provider,
    MaxTokens:      1000,
    SummaryPrompt:  "请总结以下对话的关键信息:",
    TriggerRatio:   0.8, // 当使用 80% Token 时触发压缩
})

// 创建带压缩的上下文管理器
manager := context.NewDefaultContextManagerWithCompression(tokenizer, compressor, logger)

// 自动压缩
trimmedMsgs, err := manager.TrimMessages(messages, 4096)
```

## 完整 RAG 流程

```go
// 1. 创建组件
embedder := embedding.NewOpenAIEmbedder(embeddingConfig)
vectorStore := retrieval.NewQdrantStore(qdrantConfig)
reranker := rerank.NewCohereReranker(rerankConfig)

// 2. 创建检索器
retriever := retrieval.NewHybridRetrieverWithVectorStore(
    retrieval.DefaultHybridRetrievalConfig(),
    vectorStore,
    logger,
)

// 3. 索引文档
for _, doc := range documents {
    embedding, _ := embedder.Embed(ctx, doc.Content)
    doc.Embedding = embedding
}
retriever.IndexDocuments(documents)

// 4. 检索
queryEmbedding, _ := embedder.Embed(ctx, query)
results, _ := retriever.Retrieve(ctx, query, queryEmbedding)

// 5. 重排序
rerankedResults, _ := reranker.Rerank(ctx, query, results, 5)

// 6. 构建上下文
contextBuilder := strings.Builder{}
for _, r := range rerankedResults {
    contextBuilder.WriteString(r.Document.Content)
    contextBuilder.WriteString("\n\n")
}

// 7. 生成回答
prompt := fmt.Sprintf("基于以下信息回答问题:\n\n%s\n\n问题: %s", 
    contextBuilder.String(), query)

response, _ := provider.Completion(ctx, &llm.ChatRequest{
    Messages: []llm.Message{
        {Role: llm.RoleUser, Content: prompt},
    },
})
```

## 最佳实践

1. **混合检索**：结合 BM25 和向量检索，提高召回率
2. **重排序**：使用 Cross-Encoder 重排序提高精度
3. **合理分块**：根据内容类型选择合适的分块大小
4. **元数据过滤**：利用元数据缩小检索范围
5. **上下文压缩**：长对话使用摘要压缩节省 Token
6. **缓存 Embedding**：避免重复计算，降低成本
