# 检索增强 (RAG)

AgentFlow 的 RAG 能力位于 `github.com/BaSui01/agentflow/rag`，包含：文档分块、混合检索（BM25 + 向量）、上下文检索、GraphRAG、向量存储接口与若干实现。

## 支持情况（后端/接口）

### 向量存储（VectorStore）

| 后端 | 状态 | 说明 |
|------|------|------|
| In-memory | ✅ 已实现 | 适用于测试/小规模数据 |
| Qdrant | ✅ 已实现 | REST 客户端（支持可选 `AutoCreateCollection`） |
| Pinecone | ✅ 已实现 | REST 客户端（支持通过 controller API 自动解析 host） |

### 其他组件

- **Embedding Provider**：`llm/embedding` ✅ 已实现（OpenAI/Cohere/Voyage/Jina/Gemini…）
- **Rerank Provider**：`llm/rerank` ✅ 已实现（Cohere/Voyage/Jina…）
- **GraphRAG**：✅ 核心逻辑已实现，但需要你提供 `GraphVectorStore`/`GraphEmbedder`（接口）

## 混合检索

结合 BM25 和向量检索的混合检索器：

```go
import "github.com/BaSui01/agentflow/rag"

retriever := rag.NewHybridRetriever(rag.DefaultHybridRetrievalConfig(), logger)

docs := []rag.Document{
    {
        ID:        "doc1",
        Content:   "Go 是一种静态类型的编译语言...",
        Metadata:  map[string]interface{}{"source": "wiki"},
        Embedding: embedding1,
    },
    {
        ID:        "doc2",
        Content:   "并发是 Go 的核心特性之一...",
        Metadata:  map[string]interface{}{"source": "blog"},
        Embedding: embedding2,
    },
}

_ = retriever.IndexDocuments(docs)

results, err := retriever.Retrieve(ctx, "Go 并发编程", queryEmbedding)
if err != nil {
    // handle err
}

for _, r := range results {
    fmt.Printf("文档: %s\n", r.Document.ID)
    fmt.Printf("最终分数: %.3f\n", r.FinalScore)
}
```

## 向量存储

### 内置内存向量存储（可运行）

```go
import "github.com/BaSui01/agentflow/rag"

vectorStore := rag.NewInMemoryVectorStore(logger)
retriever := rag.NewHybridRetrieverWithVectorStore(rag.DefaultHybridRetrievalConfig(), vectorStore, logger)
```

### Qdrant（已支持后端）

```go
vectorStore := rag.NewQdrantStore(rag.QdrantConfig{
    Host:                 "localhost",
    Port:                 6333,
    Collection:           "documents",
    AutoCreateCollection: true,
}, logger)
```

### Pinecone（已支持后端）

```go
vectorStore := rag.NewPineconeStore(rag.PineconeConfig{
    APIKey: os.Getenv("PINECONE_API_KEY"),
    Index:  "documents",
}, logger)
```

## Embedding 提供商（已支持）

```go
import "github.com/BaSui01/agentflow/llm/embedding"

embedder := embedding.NewOpenAIProvider(embedding.OpenAIConfig{
    APIKey: os.Getenv("OPENAI_API_KEY"),
    Model:  "text-embedding-3-large",
})

vector, err := embedder.EmbedQuery(ctx, "Go 并发编程")
vectors, err := embedder.EmbedDocuments(ctx, []string{"文本 1", "文本 2", "文本 3"})
```

## 重排序（已支持）

```go
import "github.com/BaSui01/agentflow/llm/rerank"

reranker := rerank.NewCohereProvider(rerank.CohereConfig{
    APIKey: os.Getenv("COHERE_API_KEY"),
    Model:  "rerank-multilingual-v3.0",
})

reranked, err := reranker.RerankSimple(ctx, query, documents, 10)
```

## 文档分块（已支持）

```go
import "github.com/BaSui01/agentflow/rag"

chunker := rag.NewDocumentChunker(rag.DefaultChunkingConfig(), &rag.SimpleTokenizer{}, logger)
chunks := chunker.ChunkDocument(rag.Document{ID: "doc1", Content: longDocument})
```

## 上下文检索（接口/示例）

`rag.NewContextualRetrieval(...)` 已实现，但需要你提供 `ContextProvider`（例如用 LLM 为每个 chunk 生成文档级上下文）。

## 图 RAG（接口/示例）

`rag.NewGraphRAG(...)` 已实现核心逻辑，但需要你提供 `GraphVectorStore`/`GraphEmbedder` 的具体实现（例如对接向量库和 embedding）。

## 上下文管理（已支持）

AgentFlow 的上下文工程位于 `agent/context`，提供自动压缩/截断能力：

```go
import agentcontext "github.com/BaSui01/agentflow/agent/context"

engineer := agentcontext.New(agentcontext.DefaultConfig(), logger)
trimmedMsgs, err := engineer.MustFit(ctx, messages, currentQuery)
```

> 注：更细粒度的“按策略裁剪（滑窗/按角色/按重要性）”API 与 LLM 摘要压缩接口已预留，但当前版本未以 `PruneByStrategy` 形式对外暴露。

## 完整可运行示例

参考：`examples/12_complete_rag_system/main.go`

---

## BM25 Contextual Retrieval

`rag/contextual_retrieval.go` 实现了 Anthropic 推荐的上下文检索最佳实践，为每个 chunk 添加文档级上下文，提高检索准确率 50-60%。

### 配置

```go
import "github.com/BaSui01/agentflow/rag"

config := rag.DefaultContextualRetrievalConfig()
// UseContextPrefix: true       // 为 chunk 添加上下文前缀
// UseReranking:     true       // 启用重排序
// ContextWeight:    0.4        // 上下文权重
// CacheContexts:    true       // 缓存生成的上下文
// CacheTTL:         1h         // 缓存过期时间
// ChunkSize:        500        // 分块大小
// ChunkOverlap:     50         // 重叠大小
// BM25K1:           1.2        // BM25 k1 参数（词频饱和度）
// BM25B:            0.75       // BM25 b 参数（文档长度归一化）

// 自定义 BM25 参数
config.BM25K1 = 1.5  // 增大 k1 → 更重视高频词
config.BM25B = 0.5   // 减小 b → 减弱文档长度的影响
```

### BM25 参数说明

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `BM25K1` | 1.2 | 词频饱和度参数。值越大，高频词的权重增长越慢 |
| `BM25B` | 0.75 | 文档长度归一化参数。0=不考虑长度，1=完全归一化 |

### 缓存机制

上下文检索内置缓存，避免重复调用 LLM 生成上下文：

- 缓存键：`docID + chunkHash`
- 默认 TTL：1 小时
- IDF 统计缓存：全局维护词的 IDF 值和平均文档长度

### 上下文提供器

```go
// 基于 LLM 的上下文生成器
contextProvider := rag.NewLLMContextProvider(
    func(ctx context.Context, prompt string) (string, error) {
        // 调用 LLM 生成上下文
        resp, err := provider.Completion(ctx, &llm.ChatRequest{
            Messages: []llm.Message{{Role: llm.RoleUser, Content: prompt}},
        })
        return resp.Choices[0].Message.Content, err
    },
    logger,
)
```

---

## Multi-hop 去重

`rag/multi_hop.go` 实现多跳推理链，支持迭代检索和四阶段去重。

### 配置

```go
import "github.com/BaSui01/agentflow/rag"

config := rag.MultiHopConfig{
    MaxHops:           5,              // 最大跳数
    MinHops:           2,              // 最少跳数
    HopTimeout:        30 * time.Second,
    TotalTimeout:      2 * time.Minute,
    ResultsPerHop:     10,             // 每跳检索文档数
    MinConfidence:     0.6,            // 最低置信度
    ContextWindowSize: 4096,           // 上下文窗口大小
}
```

### DedupStats 去重统计

每个 `ReasoningHop` 包含去重统计信息：

```go
type DedupStats struct {
    TotalRetrieved    int  // 原始检索结果数
    DedupByID         int  // 按 ID 去重数量
    DedupBySimilarity int  // 按内容相似度去重数量
    FinalCount        int  // 去重后最终数量
}
```

### 四阶段去重流程

1. **ID 去重**：相同文档 ID 的结果只保留最高分的
2. **内容相似度去重**：计算文本相似度，合并高度相似的结果
3. **跨 Hop 去重**：在推理链的不同跳之间去除重复文档
4. **全局统计**：`ReasoningChain` 汇总所有跳的去重统计

### 推理链

```go
// ReasoningChain 包含完整的推理过程
chain := rag.ReasoningChain{
    OriginalQuery:          "量子计算的最新进展",
    Hops:                   hops,
    TotalDedupByID:         12,  // 全局按 ID 去重数
    TotalDedupBySimilarity: 5,   // 全局按相似度去重数
    UniqueDocuments:        23,  // 最终唯一文档数
}
```

### Hop 类型

| 类型 | 说明 |
|------|------|
| `initial` | 初始查询检索 |
| `follow_up` | 基于前一跳结果的后续检索 |
| `decomposed` | 查询分解后的子查询 |
| `refinement` | 基于上下文的查询精炼 |
| `verification` | 交叉验证信息 |
| `bridging` | 概念桥接 |
