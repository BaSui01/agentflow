// 包 evaluation 提供智能体评测、实验与质量分析能力。
//
// 该包聚焦“如何客观评估 Agent 表现”，覆盖离线评测、在线实验、
// 自动判分与指标聚合等常见需求。
//
// # 核心能力
//
//   - 指标体系：内置准确率、相关性、完整性等评测指标
//   - 评测执行：支持对话/任务结果批量评测与打分
//   - A/B 实验：支持实验分流、版本对比与统计分析
//   - LLM 评审：通过模型裁判辅助主观质量打分
//   - 结果存储：支持实验结果与指标记录管理
//
// # 典型流程
//
//   1. 定义评测目标与指标
//   2. 运行评测或 A/B 实验
//   3. 收集并聚合指标
//   4. 对比分析并产出优化结论
//
// # 与 agent 协同
//
// evaluation 与 agent 运行时协同后，可建立“执行-评测-迭代”闭环：
//   - 将线上执行结果回流为评测样本
//   - 持续监控质量变化与回归风险
//   - 为模型/提示词/工具链路优化提供量化依据
package evaluation
